"""
BotBrain: RAG ãƒ™ãƒ¼ã‚¹ã®è¿”ä¿¡ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (NumPy + SentenceTransformer è»½é‡ç‰ˆ)

äº‹å‰ã«ç”Ÿæˆã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (vector_index_local.npz) ã‚’èª­ã¿è¾¼ã¿ã€
é«˜é€Ÿã«é¡ä¼¼æ¤œç´¢ã‚’è¡Œã†ã€‚Render ãªã©ã®ãƒ¡ãƒ¢ãƒª/CPUåˆ¶é™ãŒã‚ã‚‹ç’°å¢ƒå‘ã‘ã€‚
"""

import json
import time
import random  # Added for emoji injection
import numpy as np
from pathlib import Path
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted

from src.config import CHAT_PAIRS_FILE, VECTOR_INDEX_FILE, GOOGLE_API_KEY

# â”€â”€â”€ å®šæ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GENERATION_MODEL = "gemini-flash-latest"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
TOP_K = 10  # RAG ã§å–å¾—ã™ã‚‹é¡ä¼¼ä¼šè©±ã®æ•°

SYSTEM_PROMPT = """\
ã‚ãªãŸã¯ã€Œæ¾åŸç¢§ã€ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã«ã‚ã‚‹éå»ã®æ¾åŸç¢§ã®è¿”ä¿¡ï¼ˆreplyï¼‰ã®å£èª¿ã€æ–‡ä½“ã€çµµæ–‡å­—ã®ä½¿ã„æ–¹ã€é–“ã®å–ã‚Šæ–¹ã‚’å¿ å®Ÿã«æ¨¡å€£ã—ã¦ãã ã•ã„ã€‚
ãŸã ã—ã€è¿”ä¿¡å†…å®¹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ„å›³ã‚’æ±²ã¿å–ã£ã¦ã€è‡ªç„¶ãªä¼šè©±ã«ãªã‚‹ã‚ˆã†ã«ä½œæˆã—ã¦ãã ã•ã„ã€‚

## æ¾åŸç¢§ã®ã‚¹ã‚¿ã‚¤ãƒ«ã®ç‰¹å¾´
- ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿ï¼ˆã€ŒãŠã‚Œã€ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã€œã ã‚ˆã­ã€ã€Œãã‚Œãªã€ï¼‰
- èªå°¾ã¯ã€Œã€œã­ãˆã€ã€Œã€œã‚ˆãŠã€ã€Œã€œã ã­ãˆã€ãªã©ã€æ¯æ€§ã‚’æ„Ÿã˜ã‚‹ã‚ˆã†ãªå„ªã—ãæŸ”ã‚‰ã‹ã„å£èª¿ã‚’æ„è­˜ã™ã‚‹ã“ã¨ï¼ˆä¾‹ï¼šã€ŒãŒã‚“ã°ã£ã¦ã­ãˆã€ã€Œå¿ƒé…ã ã‚ˆãŠã€ã€Œå¤§ä¸ˆå¤«ã ã­ãˆã€ï¼‰ã€‚
- ç¬‘ã„è¡¨ç¾ã¯ã€Œwwwã€ã‚’ä½¿ç”¨ã™ã‚‹ãŒã€é »åº¦ã¯æ§ãˆã‚ã«ã™ã‚‹ã“ã¨ï¼ˆæ¯å›ã®è¿”ä¿¡ã«ã¯ä½¿ã‚ãªã„ï¼‰ã€‚ã€Œç¬‘ç¬‘ã€ã‚„ã€Œç¬‘ã€ã¯ä½¿ã‚ãªã„ã€‚
- è¿”ä¿¡ã¯è‡ªç„¶ä½“ã§ã€å …ããªã‚‰ãªã„ã€‚

## é‡è¦ãªãƒ«ãƒ¼ãƒ«
- è¿”ä¿¡ã¯çŸ­ãã€LINEã®ãƒãƒ£ãƒƒãƒˆã‚‰ã—ã„è‡ªç„¶ãªé•·ã•ã«ã—ã¦ãã ã•ã„ã€‚
- è¤‡æ•°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åˆ†ã‘ãŸã„å ´åˆã¯æ”¹è¡Œã§åŒºåˆ‡ã£ã¦ãã ã•ã„ã€‚
- ã€Œæ¾åŸç¢§ã§ã™ã€ã®ã‚ˆã†ãªè‡ªå·±ç´¹ä»‹ã¯ã—ãªã„ã§ãã ã•ã„ã€‚
- å‚è€ƒæƒ…å ±ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ãªã„ã§ãã ã•ã„ã€‚ã‚ãã¾ã§å£èª¿ã‚„é›°å›²æ°—ã®å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚
- å¨åœ§çš„ãªæ…‹åº¦ã¯å–ã‚‰ãšã€å¸¸ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯„ã‚Šæ·»ã†ã‚ˆã†ãªå„ªã—ã•ã‚’è¦‹ã›ã¦ãã ã•ã„ã€‚
"""


import logging
logger = logging.getLogger("uvicorn")

class BotBrain:
    """RAG + Gemini (NumPy Vector Search) ã«ã‚ˆã‚‹æ¾åŸç¢§ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€‚"""

    def __init__(self):
        # Gemini API è¨­å®š
        if not GOOGLE_API_KEY:
            # é–‹ç™ºæ™‚ã¯ã‚¨ãƒ©ãƒ¼ã«ã›ãšãƒ­ã‚°è­¦å‘Šã ã‘ã«ã™ã‚‹ãªã©ã®æŸ”è»Ÿæ€§ã‚’æŒãŸã›ã¦ã‚‚ã‚ˆã„ãŒ
            # ä»Šå›ã¯å¿…é ˆã¨ã™ã‚‹
            pass
        genai.configure(api_key=GOOGLE_API_KEY)
        masked_key = GOOGLE_API_KEY[:4] + "..." + GOOGLE_API_KEY[-4:] if len(GOOGLE_API_KEY) > 8 else "INVALID"
        logger.info(f"[BotBrain] Configured with API Key: {masked_key}")

        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        logger.info(f"[BotBrain] Loading embedding model: {EMBEDDING_MODEL} ...")
        self._embed_model = SentenceTransformer(EMBEDDING_MODEL)

        # Gemini ç”Ÿæˆãƒ¢ãƒ‡ãƒ«
        self._model = genai.GenerativeModel(
            model_name=GENERATION_MODEL,
            system_instruction=SYSTEM_PROMPT,
        )

        # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®ä¿æŒç”¨ (NumPy array)
        self.vectors = None      # shape: (N, 384)
        self.metadata = None     # list of dict

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ (ãªã‘ã‚Œã°ä½œæˆãƒˆãƒ©ã‚¤)
        self._load_or_build_index()

    def _load_or_build_index(self):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã€ç„¡ã‘ã‚Œã°ä½œæˆã™ã‚‹"""
        if VECTOR_INDEX_FILE.exists():
            logger.info(f"[BotBrain] Loading index from {VECTOR_INDEX_FILE} ...")
            try:
                data = np.load(VECTOR_INDEX_FILE, allow_pickle=True)
                self.vectors = data["vectors"]
                self.metadata = data["metadata"].tolist()
                logger.info(f"[BotBrain] Loaded {len(self.vectors)} vectors.")
            except Exception as e:
                logger.error(f"[BotBrain] Failed to load index: {e}")
                # ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã¯å†ç”Ÿæˆã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã©ã‚’æ¤œè¨
                pass

        if self.vectors is None:
            logger.info("[BotBrain] No index found. Building index (sample subset)...")
            # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚ã®è‡ªå‹•ç”Ÿæˆã¯é‡ã„ã®ã§ã€æœ¬æ¥ã¯ã“ã“ã«å…¥ã‚‰ãªã„ã‚ˆã†ã«é‹ç”¨ã™ã‚‹
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦å°‘ãªã‚ã®ä»¶æ•°ã§ä½œæˆ
            self._build_index_sample(sample_size=1000)

    def _build_index_sample(self, sample_size=None):
        """
        ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹ã€‚
        GPUãŒãªã„å ´åˆã€7ä¸‡ä»¶ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯æ•°åˆ†ã€œåæ•°åˆ†ã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        """
        if not CHAT_PAIRS_FILE.exists():
            raise FileNotFoundError(f"Chat pairs file not found: {CHAT_PAIRS_FILE}")

        with open(CHAT_PAIRS_FILE, "r", encoding="utf-8") as f:
            pairs = json.load(f)

        logger.info(f"[BotBrain] Loading {len(pairs)} items...")

        # å…¨ä»¶ä½¿ç”¨ (sample_size ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã‘ã‚Œã°)
        if sample_size:
            import random
            random.seed(42)
            target_size = min(sample_size, len(pairs))
            target_pairs = random.sample(pairs, target_size)
        else:
            target_pairs = pairs

        logger.info(f"[BotBrain] Embedding {len(target_pairs)} items locally (this may take a while)...")

        inputs = [p["input"] for p in target_pairs]

        # ãƒ­ãƒ¼ã‚«ãƒ«åŸ‹ã‚è¾¼ã¿ (ãƒãƒƒãƒå‡¦ç†ã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè‡ªå‹•ã§è¡Œã†)
        embeddings = self._embed_model.encode(inputs, convert_to_numpy=True, show_progress_bar=True, batch_size=32)

        self.vectors = embeddings
        self.metadata = target_pairs

        # ä¿å­˜
        np.savez_compressed(
            VECTOR_INDEX_FILE,
            vectors=self.vectors,
            metadata=np.array(self.metadata)
        )
        logger.info(f"[BotBrain] Index saved to {VECTOR_INDEX_FILE}")

    def generate_reply(self, message: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦è¿”ä¿¡ã‚’ç”Ÿæˆã™ã‚‹"""
        if self.vectors is None or len(self.vectors) == 0:
            return "ï¼ˆæº–å‚™ä¸­...ï¼‰"

        # 1. é¡ä¼¼æ¤œç´¢
        similar_items = self._search_similar(message, top_k=TOP_K)
        
        # ãƒ­ã‚°å‡ºåŠ›: æ¤œç´¢çµæœã‚’ç¢ºèª
        # logger.info(f"--- [RAG Context for: {message}] ---")
        # for i, item in enumerate(similar_items):
        #      logger.info(f"  Ref {i+1}: {item['input']} -> {item['reply']}")
        # logger.info("-----------------------------------")

        # 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt = self._build_prompt(message, similar_items)

        # 3. ç”Ÿæˆ
        try:
            response = self._model.generate_content(prompt)
            reply_text = response.text.strip()
            
            # 50% ã®ç¢ºç‡ã§çµµæ–‡å­—ã‚’ä»˜ä¸
            reply_text = self._inject_emoji(reply_text)
            
            return reply_text
        except ResourceExhausted:
            logger.warning("[Error] Gemini quota exceeded.")
            return "åˆ©ç”¨ä¸Šé™ã«ãªã£ã¡ã‚ƒã£ãŸã€ã€ã€ã¾ãŸåˆ©ç”¨ã§ãã‚‹ã¾ã§å°‘ã—å¾…ã£ã¦ã¦ã­ğŸ’¦"
        except Exception as e:
            logger.error(f"[Error] Gemini generation failed: {e}", exc_info=True)
            return "ã”ã‚ã‚“ã€ã¡ã‚‡ã£ã¨èª¿å­æ‚ªã„ã‹ã‚‚..."

    def _search_similar(self, query: str, top_k: int = 10) -> list[dict]:
        """NumPy ã§ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—ã‚’è¡Œã†"""
        if self.vectors is None:
            return []

        # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿
        query_vec = self._embed_model.encode(query, convert_to_numpy=True)
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®— (normalizeã•ã‚Œã¦ã„ã‚‹å‰æãŒã‚ã‚Œã° dotã®ã¿ã§è‰¯ã„ãŒã€ä»Šå›ã¯å¿µã®ãŸã‚å®šçŸ³é€šã‚Š)
        # SentenceTransformerã®encodeã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ­£è¦åŒ–ã•ã‚Œã¦ã„ãªã„ã“ã¨ãŒã‚ã‚‹ã®ã§ã€
        # util.cos_sim ã‚’ä½¿ã†ã‹ã€æ‰‹å‹•ã§è¨ˆç®—ã™ã‚‹ã€‚ã“ã“ã§ã¯æ‰‹å‹•ã§ã‚·ãƒ³ãƒ—ãƒ«ã«å®Ÿè£…ã€‚
        
        # æ­£è¦åŒ–
        norm_q = np.linalg.norm(query_vec)
        norm_v = np.linalg.norm(self.vectors, axis=1)
        
        if norm_q == 0:
            return []
            
        # (N,)
        similarities = np.dot(self.vectors, query_vec) / (norm_v * norm_q + 1e-9)

        # ä¸Šä½ top_k ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            item = self.metadata[idx]
            results.append({
                "input": item["input"],
                "reply": item["reply"],
                "score": float(similarities[idx])
            })
            
        return results

    def _inject_emoji(self, text: str) -> str:
        """
        50% ã®ç¢ºç‡ã§ã€æŒ‡å®šã•ã‚ŒãŸçµµæ–‡å­—ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸ã‚“ã§æ–‡æœ«ã«ä»˜ä¸ã™ã‚‹ã€‚
        """
        if random.random() < 0.5:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®çµµæ–‡å­—ãƒªã‚¹ãƒˆ
            emoji_list = ["ğŸ¥¹", "ğŸ’–", "ğŸ¥°", "ğŸ˜Œ", "â˜ºï¸", "ğŸ’"]
            emoji = random.choice(emoji_list)
            # æ–‡æœ«ã«ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç©ºã‘ã¦ä»˜ä¸ã™ã‚‹ã‹ã¯å¥½ã¿ã ãŒã€ä»Šå›ã¯è‡ªç„¶ã«ç¹‹ã’ã‚‹ãŸã‚ã‚¹ãƒšãƒ¼ã‚¹ãªã— or ã‚ã‚Šã‚’æ¤œè¨
            # ã“ã“ã§ã¯ã‚¹ãƒšãƒ¼ã‚¹ã‚ã‚Šã§ä»˜ä¸
            return text + " " + emoji
        return text

    def _build_prompt(self, user_message: str, similar_items: list[dict]) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦"""
        reference_lines = []
        for i, item in enumerate(similar_items, 1):
            reference_lines.append(
                f"--- å‚è€ƒ{i} ---\n"
                f"ç›¸æ‰‹: {item['input']}\n"
                f"æ¾åŸç¢§: {item['reply']}"
            )
        
        references = "\n\n".join(reference_lines)

        prompt = (
            f"## å‚è€ƒæƒ…å ±ï¼ˆéå»ã®æ¾åŸç¢§ã®ä¼šè©±ï¼‰\n"
            f"{references}\n\n"
            f"---\n"
            f"## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n"
            f"{user_message}\n\n"
            f"ä¸Šè¨˜ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦ã€æ¾åŸç¢§ã¨ã—ã¦è¿”ä¿¡ã—ã¦ãã ã•ã„ã€‚"
        )
        return prompt

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    brain = BotBrain()
    try:
        print(brain.generate_reply("ãŠã¯ã‚ˆã†"))
    except Exception as e:
        print(e)
